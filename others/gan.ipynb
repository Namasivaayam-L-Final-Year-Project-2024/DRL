{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 18:37:00.161842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/namachu/.local/lib/python3.11/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/namachu/.local/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/namachu/.local/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/namachu/.local/lib/python3.11/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/namachu/.local/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/namachu/.local/lib/python3.11/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "2023-07-13 18:37:03.954681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:03.989373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:03.989585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:03.992188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:03.992766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:03.993219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:04.063308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:04.063583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:04.063727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-13 18:37:04.063851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2795 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-07-13 18:37:04.064196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-13 18:37:04.425509: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558545ec1d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-13 18:37:04.425575: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-07-13 18:37:04.431040: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-13 18:37:04.445499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-07-13 18:37:04.570045: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fe4e2bc2a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fe4e2bc2a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`logits` and `labels` must have the same shape, received ((100, 1) vs (100, 10)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m generated_data \u001b[39m=\u001b[39m generator(noise)\n\u001b[1;32m     54\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> 55\u001b[0m     g_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlosses\u001b[39m.\u001b[39;49mbinary_crossentropy(real_data, discriminator(generated_data))\n\u001b[1;32m     57\u001b[0m optimizer_gen\u001b[39m.\u001b[39mminimize(g_loss,  var_list\u001b[39m=\u001b[39mgenerator\u001b[39m.\u001b[39mtrainable_variables, tape\u001b[39m=\u001b[39mtape)\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m: d_loss=\u001b[39m\u001b[39m{\u001b[39;00md_loss\u001b[39m}\u001b[39;00m\u001b[39m, g_loss=\u001b[39m\u001b[39m{\u001b[39;00mg_loss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/keras/losses.py:2156\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     \u001b[39mreturn\u001b[39;00m y_true \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m label_smoothing) \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m label_smoothing\n\u001b[1;32m   2151\u001b[0m y_true \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39msmart_cond\u001b[39m.\u001b[39msmart_cond(\n\u001b[1;32m   2152\u001b[0m     label_smoothing, _smooth_labels, \u001b[39mlambda\u001b[39;00m: y_true\n\u001b[1;32m   2153\u001b[0m )\n\u001b[1;32m   2155\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mmean(\n\u001b[0;32m-> 2156\u001b[0m     backend\u001b[39m.\u001b[39;49mbinary_crossentropy(y_true, y_pred, from_logits\u001b[39m=\u001b[39;49mfrom_logits),\n\u001b[1;32m   2157\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   2158\u001b[0m )\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/keras/backend.py:5707\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   5703\u001b[0m output, from_logits \u001b[39m=\u001b[39m _get_logits(\n\u001b[1;32m   5704\u001b[0m     output, from_logits, \u001b[39m\"\u001b[39m\u001b[39mSigmoid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5705\u001b[0m )\n\u001b[1;32m   5706\u001b[0m \u001b[39mif\u001b[39;00m from_logits:\n\u001b[0;32m-> 5707\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49msigmoid_cross_entropy_with_logits(\n\u001b[1;32m   5708\u001b[0m         labels\u001b[39m=\u001b[39;49mtarget, logits\u001b[39m=\u001b[39;49moutput\n\u001b[1;32m   5709\u001b[0m     )\n\u001b[1;32m   5711\u001b[0m epsilon_ \u001b[39m=\u001b[39m _constant_to_tensor(epsilon(), output\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype)\n\u001b[1;32m   5712\u001b[0m output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mclip_by_value(output, epsilon_, \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m epsilon_)\n",
      "\u001b[0;31mValueError\u001b[0m: `logits` and `labels` must have the same shape, received ((100, 1) vs (100, 10))."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, Input, Dense\n",
    "\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(128, activation='relu')\n",
    "        self.dense3 = Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(128, activation='relu')\n",
    "        self.dense3 = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "optimizer_gen = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "optimizer_disc = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train the discriminator\n",
    "    noise = tf.random.normal([100, 10])\n",
    "    generated_data = generator(noise)\n",
    "    real_data = tf.random.uniform([100, 10], minval=0, maxval=10, dtype=tf.int32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        d_loss_real = discriminator(real_data)\n",
    "        d_loss_fake = discriminator(generated_data)\n",
    "        d_loss = tf.reduce_mean(d_loss_real) - tf.reduce_mean(d_loss_fake)\n",
    "\n",
    "    optimizer_disc.minimize(d_loss,var_list=discriminator.trainable_variables, tape=tape)\n",
    "\n",
    "    # Train the generator\n",
    "    noise = tf.random.normal([100, 10])\n",
    "    generated_data = generator(noise)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        g_loss = tf.keras.losses.binary_crossentropy(real_data, discriminator(generated_data))\n",
    "\n",
    "    optimizer_gen.minimize(g_loss,  var_list=generator.trainable_variables, tape=tape)\n",
    "\n",
    "    print(f\"Epoch {epoch}: d_loss={d_loss}, g_loss={g_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
